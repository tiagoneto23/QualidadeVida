{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório de \"Qualidade de Vida em Portugal\"\n",
    "\n",
    "Este notebook apresenta a análise de dados socioeconômicos obtidos da PORDATA (Base de Dados de Portugal Contemporâneo), focando em indicadores relacionados à saúde e condições econômicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "Este relatório apresenta a análise de dados socioeconômicos obtidos da PORDATA (Base de Dados de Portugal Contemporâneo), focando em indicadores relacionados à saúde e condições econômicas. O projeto foi desenvolvido como parte do trabalho prático da disciplina de Elementos de Inteligência Artificial e Ciência de Dados da Universidade da Beira Interior.\n",
    "\n",
    "A análise foi estruturada em seis fases principais: recolha de dados, limpeza e pré-processamento, exploração de dados, análise estatística, análise de relações entre variáveis e validação dos resultados. Cada fase empregou técnicas específicas implementadas através de scripts Python, permitindo uma abordagem sistemática e reproduzível para a extração de conhecimento a partir dos dados.\n",
    "\n",
    "Os datasets analisados incluem:\n",
    "- Ganho médio mensal\n",
    "- Esperança de vida\n",
    "- Despesas com saúde\n",
    "- Percepção de saúde\n",
    "- Taxa de mortalidade evitável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fase de Recolha de Dados\n",
    "\n",
    "### Técnicas Utilizadas\n",
    "\n",
    "A fase de recolha de dados foi implementada através do script `recolha_dados.py`, que utiliza técnicas de manipulação de arquivos e leitura de dados estruturados. O script emprega a biblioteca `pandas` para carregar os datasets em formato CSV e a biblioteca `os` para navegação no sistema de arquivos.\n",
    "\n",
    "Uma técnica importante implementada nesta fase foi a detecção automática de codificação de caracteres, permitindo lidar com diferentes formatos de codificação (UTF-16LE e Latin-1) frequentemente encontrados em datasets com caracteres especiais do português. Esta abordagem foi implementada através de um mecanismo de tratamento de exceções que tenta diferentes codificações quando a leitura inicial falha.\n",
    "\n",
    "### Justificativa\n",
    "\n",
    "A implementação de um processo automatizado de recolha de dados foi essencial para garantir a reprodutibilidade da análise e facilitar futuras atualizações com novos dados. A função `recolha_dados()` centraliza este processo, permitindo que outros scripts importem os dados de forma consistente.\n",
    "\n",
    "A técnica de detecção automática de codificação foi necessária devido à presença de caracteres especiais nos nomes dos datasets e nos valores textuais, como \"ESPERANÇADEVIDA\" e \"PERCEÇAODESAUDE\". Sem este tratamento, os caracteres especiais poderiam ser interpretados incorretamente, comprometendo a integridade dos dados.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "A função `recolha_dados()` conseguiu carregar com sucesso os cinco datasets da PORDATA, identificando automaticamente a codificação correta para cada arquivo. Os datasets foram armazenados em um dicionário Python, onde as chaves são os caminhos dos arquivos e os valores são os dataframes correspondentes.\n",
    "\n",
    "Esta fase estabeleceu a base para todas as análises subsequentes, garantindo que os dados brutos estivessem disponíveis em um formato adequado para processamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fase de Limpeza e Pré-processamento\n",
    "\n",
    "### Técnicas Utilizadas\n",
    "\n",
    "A limpeza e pré-processamento dos dados foram implementados no script `limpeza_dados.py`, que utiliza técnicas de transformação e filtragem de dados. A função principal `limpar_preprocessar()` aplica uma série de operações para preparar os dados para análise:\n",
    "\n",
    "1. Padronização de nomes de colunas para facilitar o acesso\n",
    "2. Conversão de tipos de dados (anos para inteiros, valores para numéricos)\n",
    "3. Tratamento de valores ausentes (remoção de linhas sem valores e preenchimento de campos categóricos vazios)\n",
    "4. Adição de metadados específicos para cada dataset (indicador e unidade de medida)\n",
    "\n",
    "### Justificativa\n",
    "\n",
    "A fase de limpeza e pré-processamento é crucial para garantir a qualidade e consistência dos dados antes da análise. A padronização dos nomes de colunas foi necessária para unificar a estrutura dos diferentes datasets, facilitando a integração posterior.\n",
    "\n",
    "A conversão de tipos de dados foi implementada para garantir que operações matemáticas e estatísticas pudessem ser aplicadas corretamente. Por exemplo, a conversão da coluna \"Ano\" para inteiro permite ordenação cronológica adequada, enquanto a conversão da coluna \"Valor\" para numérico possibilita cálculos estatísticos.\n",
    "\n",
    "O tratamento de valores ausentes foi essencial para evitar distorções nas análises estatísticas. A decisão de remover linhas sem valores na coluna principal (\"Valor\") foi tomada para preservar a integridade das análises, enquanto o preenchimento de campos categóricos vazios com strings vazias foi adotado para manter a consistência estrutural.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "O processo de limpeza resultou em datasets estruturalmente consistentes e prontos para análise. Cada dataset foi salvo em formato CSV com o sufixo \"_limpo\", preservando os dados originais e criando versões processadas para as fases subsequentes.\n",
    "\n",
    "A função `limpar_preprocessar()` gerou um relatório detalhado do processo, incluindo o número de linhas removidas por valores ausentes e as transformações aplicadas a cada dataset. Este relatório foi salvo no arquivo \"resumo_limpeza.txt\", permitindo a verificação da qualidade do processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fase de Exploração de Dados\n",
    "\n",
    "### Técnicas Utilizadas\n",
    "\n",
    "A exploração inicial dos dados foi implementada no script `explorar_datasets.py`, que utiliza técnicas de análise descritiva e visualização para compreender a estrutura e características dos datasets. A função principal `analisar_estrutura()` aplica as seguintes técnicas:\n",
    "\n",
    "1. Análise de dimensionalidade (número de linhas e colunas)\n",
    "2. Exame das primeiras linhas para compreensão do conteúdo\n",
    "3. Análise de tipos de dados e valores nulos\n",
    "4. Estatísticas descritivas para colunas numéricas\n",
    "5. Análise de valores únicos para colunas categóricas\n",
    "\n",
    "O script utiliza a biblioteca `tabulate` para formatação tabular dos resultados, facilitando a leitura e interpretação das informações.\n",
    "\n",
    "### Justificativa\n",
    "\n",
    "A fase de exploração é fundamental para compreender a natureza dos dados antes de aplicar técnicas analíticas mais avançadas. A análise de dimensionalidade permite avaliar o volume de dados disponível para cada indicador, enquanto o exame das primeiras linhas proporciona uma visão geral do conteúdo.\n",
    "\n",
    "A análise de tipos de dados e valores nulos é essencial para identificar potenciais problemas que poderiam afetar as análises subsequentes. As estatísticas descritivas fornecem uma visão inicial da distribuição dos dados numéricos, enquanto a análise de valores únicos para colunas categóricas ajuda a compreender a diversidade de categorias presentes.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "A exploração de dados gerou um resumo abrangente para cada dataset, incluindo dimensões, estrutura de colunas e período temporal coberto. Este resumo foi consolidado no arquivo \"resumo_datasets.txt\", que serve como referência para compreender o escopo e as características dos dados.\n",
    "\n",
    "A análise revelou que os datasets cobrem diferentes períodos temporais, com o dataset de esperança de vida apresentando a maior amplitude (1960-2024) e o dataset de percepção de saúde a menor (2005-2023). Também foi identificada a presença de valores nulos em algumas colunas, confirmando a necessidade das operações de limpeza realizadas na fase anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fase de Análise Estatística\n",
    "\n",
    "### Técnicas Utilizadas\n",
    "\n",
    "A análise estatística foi implementada no script `analise_estatistica.py`, que aplica técnicas estatísticas descritivas e inferenciais para extrair insights dos dados. As principais funções incluem:\n",
    "\n",
    "1. `analise_estatistica_descritiva()`: Calcula estatísticas descritivas (média, mediana, desvio padrão, etc.) e realiza testes de normalidade (Shapiro-Wilk)\n",
    "2. `criar_visualizacoes_basicas()`: Gera histogramas e gráficos de evolução temporal para cada indicador\n",
    "3. `analisar_correlacoes()`: Calcula e visualiza a matriz de correlação entre os diferentes indicadores\n",
    "\n",
    "O script utiliza as bibliotecas `matplotlib` e `seaborn` para visualizações e `scipy.stats` para testes estatísticos.\n",
    "\n",
    "### Justificativa\n",
    "\n",
    "A análise estatística é essencial para quantificar padrões e relações nos dados. As estatísticas descritivas fornecem uma visão geral da distribuição dos valores para cada indicador, enquanto os testes de normalidade ajudam a determinar se os dados seguem uma distribuição normal, o que influencia a escolha de métodos estatísticos subsequentes.\n",
    "\n",
    "As visualizações básicas (histogramas e gráficos de evolução temporal) foram implementadas para facilitar a interpretação dos resultados estatísticos, permitindo identificar visualmente tendências e padrões que poderiam não ser evidentes apenas com números.\n",
    "\n",
    "A análise de correlação foi aplicada para identificar relações lineares entre os diferentes indicadores, fornecendo uma base para investigações mais aprofundadas nas fases subsequentes.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "A análise estatística revelou características importantes dos dados, como a distribuição não-normal da maioria dos indicadores (confirmada pelos testes de Shapiro-Wilk) e a presença de tendências temporais consistentes.\n",
    "\n",
    "Os histogramas mostraram distribuições distintas para cada indicador, com o ganho médio mensal apresentando uma distribuição mais assimétrica (positivamente enviesada) e a esperança de vida uma distribuição mais próxima da normal.\n",
    "\n",
    "A matriz de correlação identificou relações significativas entre os indicadores, destacando-se:\n",
    "- Forte correlação positiva (0.983) entre ganho médio mensal e despesas de saúde\n",
    "- Correlação positiva (0.869) entre ganho médio mensal e percepção de saúde\n",
    "- Correlação negativa (-0.798) entre esperança de vida e taxa de mortalidade evitável\n",
    "\n",
    "Estas correlações forneceram direções para a análise mais aprofundada na fase seguinte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fase de Análise de Relações\n",
    "\n",
    "### Técnicas Utilizadas\n",
    "\n",
    "A análise de relações entre variáveis foi implementada no script `analise_relacoes.py`, que aplica técnicas mais avançadas para investigar as conexões identificadas na fase anterior. As principais funções incluem:\n",
    "\n",
    "1. `criar_dataframe_integrado()`: Integra dados de diferentes datasets para análise conjunta\n",
    "2. `analisar_correlacoes()`: Realiza análise detalhada das correlações mais significativas\n",
    "3. `analisar_regressoes()`: Aplica modelos de regressão linear para quantificar relações\n",
    "4. `analisar_pca()`: Implementa Análise de Componentes Principais para redução de dimensionalidade\n",
    "5. `analisar_clusters()`: Aplica algoritmos de clustering para identificar grupos de países com características similares\n",
    "6. `analisar_tendencias_temporais()`: Examina padrões de evolução ao longo do tempo\n",
    "\n",
    "### Justificativa\n",
    "\n",
    "A análise de relações é fundamental para extrair conhecimento mais profundo dos dados, indo além das estatísticas descritivas. A integração de dados de diferentes datasets foi necessária para permitir análises conjuntas, superando a limitação de ter os indicadores em arquivos separados.\n",
    "\n",
    "A análise de regressão foi aplicada para quantificar as relações identificadas na matriz de correlação, permitindo estimar o impacto de um indicador sobre outro. Esta técnica é particularmente útil para relações com forte correlação linear.\n",
    "\n",
    "A Análise de Componentes Principais (PCA) foi implementada para lidar com a multicolinearidade entre variáveis e identificar dimensões latentes que explicam a variabilidade dos dados. Esta técnica é valiosa para reduzir a complexidade dos dados multidimensionais.\n",
    "\n",
    "A análise de clusters foi aplicada para identificar grupos de países com perfis socioeconômicos similares, permitindo uma visão mais estruturada da diversidade entre os países europeus.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "A análise de relações produziu insights significativos sobre as conexões entre os indicadores socioeconômicos:\n",
    "\n",
    "A regressão linear entre esperança de vida e taxa de mortalidade evitável resultou na equação: Taxa de mortalidade = -23.32 × Esperança de vida + 695.50, com R² = 0.637, indicando que 63.7% da variação na taxa de mortalidade evitável pode ser explicada pela esperança de vida.\n",
    "\n",
    "A Análise de Componentes Principais identificou que dois componentes principais explicam aproximadamente 85% da variância total dos dados, sugerindo que a dimensionalidade efetiva dos dados é menor que o número de indicadores originais.\n",
    "\n",
    "A análise de clusters identificou três grupos distintos de países europeus com base nos indicadores analisados:\n",
    "- Cluster 1: Países nórdicos e Europa Ocidental, caracterizados por alto ganho médio, alta esperança de vida e baixa mortalidade evitável\n",
    "- Cluster 2: Países do Sul e Leste Europeu, incluindo Portugal, com valores intermediários\n",
    "- Cluster 3: Países do Leste Europeu com indicadores socioeconômicos mais baixos\n",
    "\n",
    "A análise de tendências temporais revelou melhorias consistentes em todos os indicadores para Portugal ao longo do período analisado, com taxas de crescimento anual médias de:\n",
    "- Ganho médio mensal: +2.78%\n",
    "- Esperança de vida: +0.22%\n",
    "- Despesas de saúde: +3.44%\n",
    "- Percepção de saúde: +0.09%\n",
    "- Taxa de mortalidade evitável: -0.57%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fase de Validação dos Resultados\n",
    "\n",
    "### Técnicas Utilizadas\n",
    "\n",
    "A validação dos resultados foi implementada no script `validar_resultados.py`, que aplica técnicas para verificar a robustez e confiabilidade das análises realizadas. As principais funções incluem:\n",
    "\n",
    "1. `verificar_arquivos_resultados()`: Verifica a existência de todos os arquivos de resultados esperados\n",
    "2. `validar_consistencia_dados()`: Avalia a consistência dos dados limpos\n",
    "3. `verificar_robustez_correlacoes()`: Testa a sensibilidade das correlações à remoção de observações\n",
    "4. `validar_analises_regressao()`: Verifica os pressupostos dos modelos de regressão\n",
    "5. `verificar_tendencias_temporais()`: Avalia a consistência das tendências identificadas\n",
    "\n",
    "### Justificativa\n",
    "\n",
    "A validação é uma fase crítica para garantir a confiabilidade dos resultados e identificar potenciais limitações. A verificação da existência de arquivos garante que todas as etapas anteriores foram concluídas com sucesso, enquanto a validação da consistência dos dados confirma que a limpeza foi eficaz.\n",
    "\n",
    "A verificação da robustez das correlações é essencial para determinar se as relações identificadas são estáveis ou se são influenciadas por outliers ou pequenos conjuntos de observações. Esta técnica envolve a remoção sistemática de observações e a reavaliação das correlações.\n",
    "\n",
    "A validação das análises de regressão verifica se os pressupostos do modelo linear (linearidade, normalidade dos resíduos, homocedasticidade) são atendidos, o que é fundamental para a validade das inferências baseadas nesses modelos.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "A validação dos resultados identificou algumas limitações importantes nas análises:\n",
    "\n",
    "A verificação de robustez das correlações revelou que algumas correlações são sensíveis à remoção de observações específicas, particularmente a correlação entre percepção de saúde e taxa de mortalidade evitável, que variou significativamente quando certos países foram removidos da análise.\n",
    "\n",
    "A validação das análises de regressão identificou violações moderadas do pressuposto de normalidade dos resíduos em alguns modelos, sugerindo cautela na interpretação dos p-valores e intervalos de confiança.\n",
    "\n",
    "A verificação das tendências temporais confirmou a consistência das tendências identificadas para Portugal, com todas as tendências mantendo sua direção e significância estatística mesmo quando subconjuntos dos dados foram analisados.\n",
    "\n",
    "Estas limitações foram documentadas no relatório de validação, fornecendo uma visão transparente da confiabilidade dos resultados e orientando interpretações mais cautelosas quando necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "A análise dos dados socioeconômicos da PORDATA revelou padrões significativos e relações importantes entre os indicadores de saúde e econômicos:\n",
    "\n",
    "1. Existe uma forte associação entre condições econômicas (ganho médio mensal) e indicadores de saúde (despesas de saúde, percepção de saúde), sugerindo que melhorias econômicas tendem a se refletir positivamente na saúde da população.\n",
    "\n",
    "2. A esperança de vida está negativamente correlacionada com a taxa de mortalidade evitável, com um modelo de regressão explicando 63.7% desta relação, indicando que países com maior esperança de vida tendem a ter sistemas de saúde mais eficazes na prevenção de mortes evitáveis.\n",
    "\n",
    "3. Portugal apresenta uma evolução positiva em todos os indicadores analisados, com crescimento consistente no ganho médio mensal e nas despesas de saúde, aumento na esperança de vida e percepção de saúde, e redução na taxa de mortalidade evitável.\n",
    "\n",
    "4. A análise de clusters posicionou Portugal no grupo intermediário de países europeus, junto com outros países do Sul e alguns do Leste Europeu, indicando um perfil socioeconômico distinto dos países nórdicos e da Europa Ocidental.\n",
    "\n",
    "Estas conclusões são respaldadas por múltiplas técnicas analíticas e foram submetidas a validação para verificar sua robustez. As limitações identificadas na fase de validação foram consideradas na interpretação dos resultados, garantindo conclusões equilibradas e fundamentadas nos dados disponíveis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
